version: '3.8'

services:
  python-gpu-container-gpu0:
    build:
      context: . # Path to the Dockerfile (current directory)
      dockerfile: Dockerfile
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: "0"  # Restrict to GPU 0
      CUDA_HOME: "/usr/local/cuda"
      LD_LIBRARY_PATH: "/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
    volumes:
      - /home/siedel/data:/data
      - /home/siedel/trained_models:/trained_models
    command: /bin/bash
    tty: true

  python-gpu-container-gpu1:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "1"  # Restrict to GPU 1

  python-gpu-container-gpu2:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "2"  # Restrict to GPU 2

  python-gpu-container-gpu3:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "3"  # Restrict to GPU 3
